{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e09e80d-8f5e-453f-88a7-8036d5fadf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82769f2c-573b-40c6-ae10-15da8bc4062f",
   "metadata": {},
   "source": [
    "# Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "356dbf37-df4b-4c7b-9277-e854b6491c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final = pd.read_csv(\"cigarettes_monthly.csv\")\n",
    "\n",
    "\n",
    "final[\"market_size_month\"] = 6.685 * final[\"custcount_monthly\"]*0.2325\n",
    "final[\"prod_mkt_share\"] = final[\"total_packs\"] / final[\"market_size_month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0648d0e3-602f-4221-b706-e9f922ffbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = final.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def series_flag(df, col, dtype=\"int8\"):\n",
    "    if col in df.columns:\n",
    "        return pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(dtype)\n",
    "    return pd.Series(0, index=df.index, dtype=dtype)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "counts = (\n",
    "    df.groupby([\"store\", \"month_idx\"], observed=True)[\"prod_key\"]\n",
    "                 .transform(\"count\")\n",
    ")\n",
    "df = prod_market_m.loc[counts > 2].copy()\n",
    "\"\"\"\n",
    "\n",
    "df = df.rename(columns={\"avg_pack_price\": \"price\"})\n",
    "mkt = [\"store\",\"month_idx\"]\n",
    "\n",
    "sum_inside = df.groupby(mkt, observed=True)[\"prod_mkt_share\"].transform(\"sum\")\n",
    "df = df[(df[\"prod_mkt_share\"] > 0) & (sum_inside < 1)].copy()\n",
    "df[\"s0\"]    = np.clip(1.0 - sum_inside, 1e-12, 1 - 1e-12)\n",
    "df[\"log_s\"] = np.log(df[\"prod_mkt_share\"]) - np.log(df[\"s0\"])\n",
    "\n",
    "if \"prod_id\" not in df.columns:\n",
    "    if \"upc_norm\" in df.columns:\n",
    "        df[\"prod_id\"] = df[\"upc_norm\"].astype(\"string\")\n",
    "    elif \"upc\" in df.columns:\n",
    "        df[\"prod_id\"] = df[\"upc\"].astype(\"string\").str.replace(r\"\\D\",\"\", regex=True)\n",
    "    else:\n",
    "        df[\"prod_id\"] = df.index.astype(\"string\")\n",
    "\n",
    "brand_raw = df.get(\"brand\", pd.Series(\"\", index=df.index))\n",
    "brand_key = (brand_raw.astype(\"string\").str.strip().str.lower()\n",
    "             .mask(lambda s: s.eq(\"\") | s.isna(), \"generic\"))\n",
    "is_generic = (series_flag(df, \"generic_hardcoded\") > 0) | brand_key.eq(\"generic\")\n",
    "brand_key  = brand_key.mask(is_generic, \"generic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26a17734-3df5-48dc-89ae-39f85cf26645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OLS Nested Logit | Market FE absorbed]\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "price           0.0333      0.021      1.615      0.106      -0.007       0.074\n",
      "ln_s_within     0.9337      0.003    309.996      0.000       0.928       0.940\n",
      "slim            0.3884      0.071      5.434      0.000       0.248       0.528\n",
      "value          -1.0275      0.051    -20.114      0.000      -1.128      -0.927\n",
      "premium         0.1379      0.013     10.575      0.000       0.112       0.163\n",
      "flavored       -0.2744      0.020    -13.476      0.000      -0.314      -0.234\n",
      "carton          0.0370      0.016      2.323      0.020       0.006       0.068\n",
      "tar_mean       -0.0099      0.021     -0.465      0.642      -0.052       0.032\n",
      "nic_mean        0.5580      0.449      1.244      0.214      -0.321       1.437\n",
      "co_mean        -0.2358      0.023    -10.114      0.000      -0.282      -0.190\n",
      "===============================================================================\n",
      "\n",
      "[IV Nested Logit | Market FE absorbed | Hausman + BLP(cont) + Nest(cont)]\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                   ln_s   R-squared:                      0.5744\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.5743\n",
      "No. Observations:               55387   F-statistic:                 1.541e+04\n",
      "Date:                Sat, Nov 08 2025   P-value (F-stat)                0.0000\n",
      "Time:                        21:06:05   Distribution:                 chi2(10)\n",
      "Cov. Estimator:             clustered                                         \n",
      "                                                                              \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "slim            1.4758     0.0603     24.456     0.0000      1.3575      1.5940\n",
      "value          -1.5793     0.0562    -28.116     0.0000     -1.6894     -1.4692\n",
      "premium        -0.2714     0.0299    -9.0888     0.0000     -0.3300     -0.2129\n",
      "flavored        0.0100     0.0367     0.2726     0.7851     -0.0619      0.0819\n",
      "carton          0.3681     0.0304     12.103     0.0000      0.3085      0.4277\n",
      "tar_mean        0.4279     0.0202     21.134     0.0000      0.3882      0.4675\n",
      "nic_mean       -10.923     0.4661    -23.434     0.0000     -11.837     -10.009\n",
      "co_mean        -0.2643     0.0138    -19.103     0.0000     -0.2914     -0.2372\n",
      "price          -0.6709     0.0562    -11.936     0.0000     -0.7811     -0.5607\n",
      "ln_s_within     0.2250     0.0221     10.184     0.0000      0.1817      0.2683\n",
      "===============================================================================\n",
      "\n",
      "Endogenous: price, ln_s_within\n",
      "Instruments: z_haus, iv_brand_riv_sum_tar_mean, iv_brand_riv_sum_nic_mean, iv_brand_riv_sum_co_mean, iv_rival_count, iv_nest_same_sum_tar_mean, iv_nest_same_sum_nic_mean, iv_nest_same_sum_co_mean, iv_nest_same_cnt\n",
      "Clustered Covariance (One-Way)\n",
      "Debiased: False\n",
      "Num Clusters: 93\n",
      "\n",
      "[First stages]\n",
      "           First Stage Estimation Results          \n",
      "===================================================\n",
      "                                  price ln_s_within\n",
      "---------------------------------------------------\n",
      "R-squared                        0.9257      0.3373\n",
      "Partial R-squared                0.8516      0.0795\n",
      "Shea's R-squared                 0.5595      0.0523\n",
      "Partial F-statistic           2.277e+04      1757.1\n",
      "P-value (Partial F-stat)         0.0000      0.0000\n",
      "Partial F-stat Distn            chi2(9)     chi2(9)\n",
      "=========================== =========== ===========\n",
      "slim                            -0.0445      1.4881\n",
      "                              (-3.9588)    (14.348)\n",
      "value                            0.0028     -1.6598\n",
      "                               (0.2770)   (-18.757)\n",
      "premium                          0.0050     -0.3826\n",
      "                               (1.2799)   (-9.9625)\n",
      "flavored                        -0.0039      0.0948\n",
      "                              (-0.5930)    (1.4186)\n",
      "carton                          -0.0157      0.3950\n",
      "                              (-1.6839)    (9.5995)\n",
      "tar_mean                        -0.0100      0.1997\n",
      "                              (-2.2024)    (7.2415)\n",
      "nic_mean                         0.2080     -6.1651\n",
      "                               (2.2234)   (-11.494)\n",
      "co_mean                          0.0068     -0.4438\n",
      "                               (2.2448)   (-18.568)\n",
      "z_haus                           0.2465     -0.2170\n",
      "                               (115.07)   (-16.759)\n",
      "iv_brand_riv_sum_tar_mean       -0.0085     -1.7901\n",
      "                              (-0.2727)   (-6.6288)\n",
      "iv_brand_riv_sum_nic_mean        0.0086      3.3534\n",
      "                               (0.1928)    (8.8099)\n",
      "iv_brand_riv_sum_co_mean        -0.0356     -1.9698\n",
      "                              (-3.8201)   (-10.599)\n",
      "iv_rival_count                   0.0364      0.3590\n",
      "                               (2.6423)    (1.5523)\n",
      "iv_nest_same_sum_tar_mean       -0.4677     -13.703\n",
      "                              (-3.0438)   (-11.272)\n",
      "iv_nest_same_sum_nic_mean        0.6145      21.490\n",
      "                               (2.6371)    (11.478)\n",
      "iv_nest_same_sum_co_mean        -0.2003      0.4349\n",
      "                              (-2.8709)    (0.6553)\n",
      "iv_nest_same_cnt                 0.0528     -8.6100\n",
      "                               (0.5543)   (-12.851)\n",
      "---------------------------------------------------\n",
      "\n",
      "T-stats reported in parentheses\n",
      "T-stats use same covariance type as original model\n",
      "\n",
      "σ (nesting): 0.225 | implied avg own-price elasticity ≈ 1.34\n",
      "\n",
      "Brand × Brand elasticities (continuous long format)\n",
      " affected_brand   shocked_brand price_elasticity_pct flavored_semi_delta\n",
      "benson & hedges benson & hedges             -166.373            -0.00000\n",
      "benson & hedges         generic                0.081             0.00000\n",
      "benson & hedges            kool                0.023             0.00000\n",
      "benson & hedges        marlboro                0.284             0.00000\n",
      "benson & hedges  virginia slims                0.026             0.00000\n",
      "benson & hedges         winston                0.005             0.00000\n",
      "benson & hedges  winston select                0.003             0.00000\n",
      "          doral           doral             -287.147            -0.00000\n",
      "          doral         generic                0.117             0.00000\n",
      "        generic benson & hedges                0.056             0.00000\n",
      "        generic           doral                0.003             0.00000\n",
      "        generic         generic             -152.357             0.00000\n",
      "        generic            kool                0.023             0.00000\n",
      "        generic        marlboro                0.281             0.00000\n",
      "        generic  virginia slims                0.026             0.00000\n",
      "        generic         winston                0.030             0.00000\n",
      "        generic  winston select                0.008             0.00000\n",
      "           kool benson & hedges                0.056             0.00000\n",
      "           kool         generic                0.081             0.00000\n",
      "           kool            kool             -173.717            -0.00000\n",
      "           kool        marlboro                0.282             0.00000\n",
      "           kool  virginia slims                0.026             0.00000\n",
      "           kool         winston                0.005             0.00000\n",
      "           kool  winston select                0.003             0.00000\n",
      "       marlboro benson & hedges                0.056             0.00000\n",
      "       marlboro         generic                0.081             0.00000\n",
      "       marlboro            kool                0.023             0.00000\n",
      "       marlboro        marlboro             -172.078             0.00000\n",
      "       marlboro  virginia slims                0.026             0.00000\n",
      "       marlboro         winston                0.005             0.00000\n",
      "       marlboro  winston select                0.003             0.00000\n",
      " virginia slims benson & hedges                0.057             0.00000\n",
      " virginia slims         generic                0.080             0.00000\n",
      " virginia slims            kool                0.023             0.00000\n",
      " virginia slims        marlboro                0.292             0.00000\n",
      " virginia slims  virginia slims             -167.509             0.00000\n",
      " virginia slims         winston                0.005             0.00000\n",
      " virginia slims  winston select                0.003             0.00000\n",
      "        winston benson & hedges                0.082             0.00000\n",
      "        winston         generic                0.078             0.00000\n",
      "        winston            kool                0.054             0.00000\n",
      "        winston        marlboro                0.464             0.00000\n",
      "        winston  virginia slims                0.047             0.00000\n",
      "        winston         winston             -107.442             0.00000\n",
      "        winston  winston select                0.004             0.00000\n",
      " winston select benson & hedges                0.066             0.00000\n",
      " winston select         generic                0.077             0.00000\n",
      " winston select            kool                0.024             0.00000\n",
      " winston select        marlboro                0.316             0.00000\n",
      " winston select  virginia slims                0.029             0.00000\n",
      " winston select         winston                0.061             0.00000\n",
      " winston select  winston select             -140.980             0.00000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.iv import IV2SLS\n",
    "\n",
    "# ## Nested Logit\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.iv import IV2SLS\n",
    "\n",
    "# -----------------------\n",
    "# helpers\n",
    "# -----------------------\n",
    "def series_flag(df, col, dtype=\"int8\"):\n",
    "    if col in df.columns:\n",
    "        return pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(dtype)\n",
    "    return pd.Series(0, index=df.index, dtype=dtype)\n",
    "\n",
    "def demean_within(frame, cols, keys):\n",
    "    means = frame.groupby(keys, observed=True)[cols].transform(\"mean\")\n",
    "    return frame[cols] - means\n",
    "\n",
    "def prune_instruments_for_full_rank(exog_df, Z_df, tol=1e-10):\n",
    "    W, keep = exog_df.copy(), []\n",
    "    for c in Z_df.columns:\n",
    "        r_old = np.linalg.matrix_rank(W.to_numpy(), tol)\n",
    "        W_try = pd.concat([W, Z_df[[c]]], axis=1)\n",
    "        r_new = np.linalg.matrix_rank(W_try.to_numpy(), tol)\n",
    "        if r_new > r_old:\n",
    "            keep.append(c); W = W_try\n",
    "    return Z_df[keep]\n",
    "\n",
    "def standardize_cols(df):\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        s = float(out[c].std(skipna=True))\n",
    "        if np.isfinite(s) and s > 0:\n",
    "            out[c] = out[c] / s\n",
    "    return out\n",
    "\n",
    "# ========================\n",
    "# 0) data & keys\n",
    "# ========================\n",
    "df = final.copy()\n",
    "df = df.rename(columns={\"avg_pack_price\": \"price\"})\n",
    "mkt = [\"store\",\"month_idx\"]\n",
    "\n",
    "# inside/outside shares\n",
    "sum_inside = df.groupby(mkt, observed=True)[\"prod_mkt_share\"].transform(\"sum\")\n",
    "df = df[(df[\"prod_mkt_share\"] > 0) & (sum_inside < 1)].copy()\n",
    "df[\"s0\"] = np.clip(1.0 - sum_inside, 1e-12, 1 - 1e-12)\n",
    "\n",
    "# ids\n",
    "if \"prod_id\" not in df.columns:\n",
    "    if \"upc_norm\" in df.columns:\n",
    "        df[\"prod_id\"] = df[\"upc_norm\"].astype(\"string\")\n",
    "    elif \"upc\" in df.columns:\n",
    "        df[\"prod_id\"] = df[\"upc\"].astype(\"string\").str.replace(r\"\\D\",\"\", regex=True)\n",
    "    else:\n",
    "        df[\"prod_id\"] = df.index.astype(\"string\")\n",
    "\n",
    "# brand vs generic; nest = branded/generic\n",
    "brand_raw = df.get(\"brand\", pd.Series(\"\", index=df.index))\n",
    "brand_key = (brand_raw.astype(\"string\").str.strip().str.lower()\n",
    "             .mask(lambda s: s.eq(\"\") | s.isna(), \"generic\"))\n",
    "is_generic = (series_flag(df, \"generic_hardcoded\") > 0) | brand_key.eq(\"generic\")\n",
    "brand_key  = brand_key.mask(is_generic, \"generic\")\n",
    "df[\"nest\"] = np.where(brand_key.eq(\"generic\"), \"generic\", \"branded\")\n",
    "\n",
    "# ========================\n",
    "# 1) nested-logit shares (RAW)\n",
    "# ========================\n",
    "# ln s_j - ln s_0\n",
    "df[\"ln_s\"] = np.log(df[\"prod_mkt_share\"]) - np.log(df[\"s0\"])\n",
    "# within-nest share s_{j|g} and its log\n",
    "sg = df.groupby(mkt + [\"nest\"], observed=True)[\"prod_mkt_share\"].transform(\"sum\")\n",
    "df = df[sg > 0].copy()\n",
    "df[\"ln_s_within\"] = np.log(df[\"prod_mkt_share\"]) - np.log(sg)\n",
    "\n",
    "# regressors\n",
    "dummy_cols = [c for c in [\"dlx\",\"supslim\",\"slim\",\"value\",\"premium\",\"flavored\",\"carton\"] if c in df.columns]\n",
    "cont_cols  = [c for c in [\"tar_mean\",\"nic_mean\",\"co_mean\"] if c in df.columns]\n",
    "Xnames     = [\"price\",\"ln_s_within\"] + dummy_cols + cont_cols\n",
    "\n",
    "need = [\"ln_s\",\"price\",\"store\",\"month_idx\",\"nest\",\"prod_id\"] + Xnames\n",
    "df2  = df.dropna(subset=need).copy()\n",
    "df2[\"brand_for_iv\"] = brand_key.loc[df2.index].astype(\"string\")\n",
    "\n",
    "# ========================\n",
    "# 2) instruments (RAW) – Hausman + BLP(cont) + Nest(cont)\n",
    "# ========================\n",
    "# --- Hausman (coalesced z1 -> z2 -> z3) ---\n",
    "g_uq = df2.groupby([\"prod_id\",\"month_idx\"], observed=True)\n",
    "cnt_uq = g_uq[\"price\"].transform(\"count\"); sum_uq = g_uq[\"price\"].transform(\"sum\")\n",
    "z1_raw = np.where(cnt_uq.gt(1), (sum_uq - df2[\"price\"]) / (cnt_uq - 1), np.nan)\n",
    "\n",
    "g_u  = df2.groupby([\"prod_id\"], observed=True)\n",
    "cnt_u = g_u[\"price\"].transform(\"count\"); sum_u = g_u[\"price\"].transform(\"sum\")\n",
    "g_us = df2.groupby([\"prod_id\",\"store\"], observed=True)\n",
    "cnt_us = g_us[\"price\"].transform(\"count\"); sum_us = g_us[\"price\"].transform(\"sum\")\n",
    "z2_raw = np.where((cnt_u - cnt_us).gt(0), (sum_u - sum_us) / (cnt_u - cnt_us), np.nan)\n",
    "\n",
    "gbm  = df2.groupby([\"brand_for_iv\",\"month_idx\"], observed=True)\n",
    "cnt_bm = gbm[\"price\"].transform(\"count\"); sum_bm = gbm[\"price\"].transform(\"sum\")\n",
    "gbms = df2.groupby([\"brand_for_iv\",\"month_idx\",\"store\"], observed=True)\n",
    "cnt_bms = gbms[\"price\"].transform(\"count\"); sum_bms = gbms[\"price\"].transform(\"sum\")\n",
    "z3_raw = np.where((cnt_bm - cnt_bms).gt(0), (sum_bm - sum_bms) / (cnt_bm - cnt_bms), np.nan)\n",
    "\n",
    "z_haus_raw = pd.Series(z1_raw, index=df2.index)\n",
    "z_haus_raw = z_haus_raw.where(z_haus_raw.notna(), pd.Series(z2_raw, index=df2.index))\n",
    "z_haus_raw = z_haus_raw.where(z_haus_raw.notna(), pd.Series(z3_raw, index=df2.index))\n",
    "\n",
    "Z_raw = pd.DataFrame({\"z_haus\": z_haus_raw}, index=df2.index)\n",
    "\n",
    "# --- BLP(cont) by brand (as in simple logit) ---\n",
    "gm  = df2.groupby(mkt, observed=True)\n",
    "gfb = df2.groupby(mkt + [\"brand_for_iv\"], observed=True)\n",
    "for c in cont_cols:\n",
    "    tot = gm[c].transform(\"sum\")\n",
    "    own = gfb[c].transform(\"sum\")\n",
    "    Z_raw[f\"iv_brand_riv_sum_{c}\"] = tot - own\n",
    "    Z_raw[f\"iv_brand_own_sum_{c}\"] = own - df2[c]\n",
    "# rival count in market (helps 1st stage)\n",
    "Z_raw[\"iv_rival_count\"] = gm[\"price\"].transform(\"size\") - gfb[\"price\"].transform(\"size\")\n",
    "\n",
    "# --- Nest(cont) proxies for ln_s_within (same-nest & other-nest sums/counts) ---\n",
    "gmn = df2.groupby(mkt + [\"nest\"], observed=True)\n",
    "for c in cont_cols:\n",
    "    nest_tot = gmn[c].transform(\"sum\")\n",
    "    Z_raw[f\"iv_nest_same_sum_{c}\"]  = nest_tot - df2[c]\n",
    "    Z_raw[f\"iv_nest_other_sum_{c}\"] = gm[c].transform(\"sum\") - nest_tot\n",
    "# counts\n",
    "Z_raw[\"iv_nest_same_cnt\"]  = gmn[\"price\"].transform(\"size\") - 1\n",
    "Z_raw[\"iv_nest_other_cnt\"] = gm[\"price\"].transform(\"size\") - gmn[\"price\"].transform(\"size\")\n",
    "\n",
    "# ========================\n",
    "# 3) ONE FE removal for y, X, Z\n",
    "# ========================\n",
    "X_tilde = demean_within(df2, Xnames, mkt)\n",
    "y_tilde = (df2[\"ln_s\"] - df2.groupby(mkt, observed=True)[\"ln_s\"].transform(\"mean\")).rename(\"ln_s\")\n",
    "Z_tilde = demean_within(pd.concat([df2[mkt], Z_raw], axis=1), list(Z_raw.columns), mkt)\n",
    "\n",
    "# single estimation sample\n",
    "all_parts = pd.concat([y_tilde, X_tilde, Z_tilde], axis=1).replace([np.inf,-np.inf], np.nan).dropna()\n",
    "y_iv  = all_parts[\"ln_s\"]\n",
    "X_iv  = all_parts[Xnames]\n",
    "Z_iv  = all_parts[Z_tilde.columns]\n",
    "\n",
    "# drop zero-variance cols; standardize IVs; prune for rank\n",
    "X_iv = X_iv.loc[:, X_iv.apply(lambda s: np.nanstd(s.to_numpy()) > 0)]\n",
    "Z_iv = standardize_cols(Z_iv.loc[:, Z_iv.apply(lambda s: np.nanstd(s.to_numpy()) > 0)])\n",
    "\n",
    "# endogenous: price & ln_s_within\n",
    "exog  = X_iv.drop(columns=[\"price\",\"ln_s_within\"])\n",
    "Z_iv  = prune_instruments_for_full_rank(exog, Z_iv)\n",
    "\n",
    "clusters_iv = pd.to_numeric(df2.loc[all_parts.index, \"store\"], errors=\"coerce\").astype(int).to_numpy()\n",
    "\n",
    "# ========================\n",
    "# 4) Estimation\n",
    "# ========================\n",
    "ols = sm.OLS(y_iv, X_iv).fit(cov_type=\"cluster\", cov_kwds={\"groups\": clusters_iv})\n",
    "print(\"\\n[OLS Nested Logit | Market FE absorbed]\")\n",
    "print(ols.summary().tables[1])\n",
    "\n",
    "iv = IV2SLS(\n",
    "    dependent=y_iv,\n",
    "    exog=exog,\n",
    "    endog=X_iv[[\"price\",\"ln_s_within\"]],\n",
    "    instruments=Z_iv\n",
    ").fit(cov_type=\"clustered\", clusters=clusters_iv)\n",
    "print(\"\\n[IV Nested Logit | Market FE absorbed | Hausman + BLP(cont) + Nest(cont)]\")\n",
    "#print(iv.summary)\n",
    "try:\n",
    "  #  print(\"\\n[First stages]\"); print(iv.first_stage.summary)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# quick elasticity diagnostic\n",
    "sigma = float(iv.params.get(\"ln_s_within\", np.nan))\n",
    "alpha = float(iv.params.get(\"price\", np.nan))\n",
    "sbar   = float(df2.loc[all_parts.index, \"prod_mkt_share\"].mean())\n",
    "sjgbar = float((df2.loc[all_parts.index, \"prod_mkt_share\"] /\n",
    "                df2.loc[all_parts.index].groupby(mkt + [\"nest\"], observed=True)[\"prod_mkt_share\"].transform(\"sum\")).mean())\n",
    "pbar   = float(df2.loc[all_parts.index, \"price\"].mean())\n",
    "eps    = -alpha * pbar * (1 - sigma*(1 - sjgbar) - sbar)\n",
    "print(f\"\\nσ (nesting): {sigma:.3f} | implied avg own-price elasticity ≈ {eps:.2f}\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bcde165-7f5c-479e-a13d-dbdc79cc7d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_37ad6_ th.col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_37ad6_ th.row_heading {\n",
       "  text-align: right;\n",
       "}\n",
       "#T_37ad6_row0_col0 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37ad6_row0_col1, #T_37ad6_row0_col2, #T_37ad6_row0_col3, #T_37ad6_row0_col4, #T_37ad6_row0_col5, #T_37ad6_row0_col6, #T_37ad6_row0_col7, #T_37ad6_row1_col0, #T_37ad6_row1_col2, #T_37ad6_row1_col3, #T_37ad6_row1_col4, #T_37ad6_row1_col5, #T_37ad6_row1_col6, #T_37ad6_row1_col7, #T_37ad6_row2_col0, #T_37ad6_row2_col1, #T_37ad6_row2_col3, #T_37ad6_row2_col4, #T_37ad6_row2_col5, #T_37ad6_row2_col6, #T_37ad6_row2_col7, #T_37ad6_row3_col0, #T_37ad6_row3_col1, #T_37ad6_row3_col2, #T_37ad6_row3_col4, #T_37ad6_row3_col5, #T_37ad6_row3_col6, #T_37ad6_row3_col7, #T_37ad6_row4_col0, #T_37ad6_row4_col1, #T_37ad6_row4_col2, #T_37ad6_row4_col3, #T_37ad6_row4_col5, #T_37ad6_row4_col6, #T_37ad6_row4_col7, #T_37ad6_row5_col0, #T_37ad6_row5_col1, #T_37ad6_row5_col2, #T_37ad6_row5_col3, #T_37ad6_row5_col4, #T_37ad6_row5_col6, #T_37ad6_row5_col7, #T_37ad6_row6_col0, #T_37ad6_row6_col1, #T_37ad6_row6_col2, #T_37ad6_row6_col3, #T_37ad6_row6_col4, #T_37ad6_row6_col5, #T_37ad6_row6_col7, #T_37ad6_row7_col0, #T_37ad6_row7_col1, #T_37ad6_row7_col2, #T_37ad6_row7_col3, #T_37ad6_row7_col4, #T_37ad6_row7_col5, #T_37ad6_row7_col6 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37ad6_row1_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37ad6_row2_col2 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37ad6_row3_col3 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37ad6_row4_col4 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37ad6_row5_col5 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37ad6_row6_col6 {\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37ad6_row7_col7 {\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_37ad6_\">\n",
       "  <caption>Brand × Brand PRICE Elasticities (% ΔS_b for 1% ↑ price of brand c)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >benson & hedges</th>\n",
       "      <th class=\"col_heading level0 col1\" >doral</th>\n",
       "      <th class=\"col_heading level0 col2\" >generic</th>\n",
       "      <th class=\"col_heading level0 col3\" >kool</th>\n",
       "      <th class=\"col_heading level0 col4\" >marlboro</th>\n",
       "      <th class=\"col_heading level0 col5\" >virginia slims</th>\n",
       "      <th class=\"col_heading level0 col6\" >winston</th>\n",
       "      <th class=\"col_heading level0 col7\" >winston select</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row0\" class=\"row_heading level0 row0\" >benson & hedges</th>\n",
       "      <td id=\"T_37ad6_row0_col0\" class=\"data row0 col0\" >-1.66%</td>\n",
       "      <td id=\"T_37ad6_row0_col1\" class=\"data row0 col1\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row0_col2\" class=\"data row0 col2\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row0_col3\" class=\"data row0 col3\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row0_col4\" class=\"data row0 col4\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row0_col6\" class=\"data row0 col6\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row0_col7\" class=\"data row0 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row1\" class=\"row_heading level0 row1\" >doral</th>\n",
       "      <td id=\"T_37ad6_row1_col0\" class=\"data row1 col0\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row1_col1\" class=\"data row1 col1\" >-2.87%</td>\n",
       "      <td id=\"T_37ad6_row1_col2\" class=\"data row1 col2\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row1_col3\" class=\"data row1 col3\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row1_col4\" class=\"data row1 col4\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row1_col6\" class=\"data row1 col6\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row1_col7\" class=\"data row1 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row2\" class=\"row_heading level0 row2\" >generic</th>\n",
       "      <td id=\"T_37ad6_row2_col0\" class=\"data row2 col0\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row2_col1\" class=\"data row2 col1\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row2_col2\" class=\"data row2 col2\" >-1.52%</td>\n",
       "      <td id=\"T_37ad6_row2_col3\" class=\"data row2 col3\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row2_col4\" class=\"data row2 col4\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row2_col5\" class=\"data row2 col5\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row2_col6\" class=\"data row2 col6\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row2_col7\" class=\"data row2 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row3\" class=\"row_heading level0 row3\" >kool</th>\n",
       "      <td id=\"T_37ad6_row3_col0\" class=\"data row3 col0\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row3_col1\" class=\"data row3 col1\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row3_col2\" class=\"data row3 col2\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row3_col3\" class=\"data row3 col3\" >-1.74%</td>\n",
       "      <td id=\"T_37ad6_row3_col4\" class=\"data row3 col4\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row3_col5\" class=\"data row3 col5\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row3_col6\" class=\"data row3 col6\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row3_col7\" class=\"data row3 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row4\" class=\"row_heading level0 row4\" >marlboro</th>\n",
       "      <td id=\"T_37ad6_row4_col0\" class=\"data row4 col0\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row4_col1\" class=\"data row4 col1\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row4_col2\" class=\"data row4 col2\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row4_col3\" class=\"data row4 col3\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row4_col4\" class=\"data row4 col4\" >-1.72%</td>\n",
       "      <td id=\"T_37ad6_row4_col5\" class=\"data row4 col5\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row4_col6\" class=\"data row4 col6\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row4_col7\" class=\"data row4 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row5\" class=\"row_heading level0 row5\" >virginia slims</th>\n",
       "      <td id=\"T_37ad6_row5_col0\" class=\"data row5 col0\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row5_col1\" class=\"data row5 col1\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row5_col2\" class=\"data row5 col2\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row5_col3\" class=\"data row5 col3\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row5_col4\" class=\"data row5 col4\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row5_col5\" class=\"data row5 col5\" >-1.68%</td>\n",
       "      <td id=\"T_37ad6_row5_col6\" class=\"data row5 col6\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row5_col7\" class=\"data row5 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row6\" class=\"row_heading level0 row6\" >winston</th>\n",
       "      <td id=\"T_37ad6_row6_col0\" class=\"data row6 col0\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row6_col1\" class=\"data row6 col1\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row6_col2\" class=\"data row6 col2\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row6_col3\" class=\"data row6 col3\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row6_col4\" class=\"data row6 col4\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row6_col5\" class=\"data row6 col5\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row6_col6\" class=\"data row6 col6\" >-1.07%</td>\n",
       "      <td id=\"T_37ad6_row6_col7\" class=\"data row6 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37ad6_level0_row7\" class=\"row_heading level0 row7\" >winston select</th>\n",
       "      <td id=\"T_37ad6_row7_col0\" class=\"data row7 col0\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row7_col1\" class=\"data row7 col1\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row7_col2\" class=\"data row7 col2\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row7_col3\" class=\"data row7 col3\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row7_col4\" class=\"data row7 col4\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row7_col5\" class=\"data row7 col5\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row7_col6\" class=\"data row7 col6\" >0.00%</td>\n",
       "      <td id=\"T_37ad6_row7_col7\" class=\"data row7 col7\" >-1.41%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dd854a2ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dd266_ th.col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_dd266_ th.row_heading {\n",
       "  text-align: right;\n",
       "}\n",
       "#T_dd266_row0_col0, #T_dd266_row0_col1, #T_dd266_row1_col0, #T_dd266_row1_col3, #T_dd266_row1_col4, #T_dd266_row1_col5, #T_dd266_row1_col6, #T_dd266_row1_col7, #T_dd266_row3_col1, #T_dd266_row4_col1, #T_dd266_row5_col1, #T_dd266_row6_col1, #T_dd266_row7_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dd266_row0_col2, #T_dd266_row0_col3, #T_dd266_row0_col4, #T_dd266_row0_col5, #T_dd266_row0_col6, #T_dd266_row0_col7, #T_dd266_row1_col2, #T_dd266_row2_col0, #T_dd266_row2_col1, #T_dd266_row2_col2, #T_dd266_row2_col3, #T_dd266_row2_col4, #T_dd266_row2_col5, #T_dd266_row2_col6, #T_dd266_row2_col7, #T_dd266_row3_col0, #T_dd266_row3_col2, #T_dd266_row3_col4, #T_dd266_row3_col5, #T_dd266_row3_col6, #T_dd266_row3_col7, #T_dd266_row4_col0, #T_dd266_row4_col2, #T_dd266_row4_col3, #T_dd266_row4_col4, #T_dd266_row4_col5, #T_dd266_row4_col6, #T_dd266_row4_col7, #T_dd266_row5_col0, #T_dd266_row5_col2, #T_dd266_row5_col3, #T_dd266_row5_col4, #T_dd266_row5_col5, #T_dd266_row5_col6, #T_dd266_row5_col7, #T_dd266_row6_col0, #T_dd266_row6_col2, #T_dd266_row6_col3, #T_dd266_row6_col4, #T_dd266_row6_col5, #T_dd266_row6_col6, #T_dd266_row6_col7, #T_dd266_row7_col0, #T_dd266_row7_col2, #T_dd266_row7_col3, #T_dd266_row7_col4, #T_dd266_row7_col5, #T_dd266_row7_col6, #T_dd266_row7_col7 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dd266_row1_col1 {\n",
       "  background-color: #005723;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dd266_row3_col3 {\n",
       "  background-color: #aadda4;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dd266_\">\n",
       "  <caption>Brand × Brand FLAVORED Semi-Elasticities (ΔS_b when brand c flavored is banned)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >benson & hedges</th>\n",
       "      <th class=\"col_heading level0 col1\" >doral</th>\n",
       "      <th class=\"col_heading level0 col2\" >generic</th>\n",
       "      <th class=\"col_heading level0 col3\" >kool</th>\n",
       "      <th class=\"col_heading level0 col4\" >marlboro</th>\n",
       "      <th class=\"col_heading level0 col5\" >virginia slims</th>\n",
       "      <th class=\"col_heading level0 col6\" >winston</th>\n",
       "      <th class=\"col_heading level0 col7\" >winston select</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row0\" class=\"row_heading level0 row0\" >benson & hedges</th>\n",
       "      <td id=\"T_dd266_row0_col0\" class=\"data row0 col0\" >-0.0000</td>\n",
       "      <td id=\"T_dd266_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_dd266_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row0_col3\" class=\"data row0 col3\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row0_col5\" class=\"data row0 col5\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row1\" class=\"row_heading level0 row1\" >doral</th>\n",
       "      <td id=\"T_dd266_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_dd266_row1_col1\" class=\"data row1 col1\" >-0.0000</td>\n",
       "      <td id=\"T_dd266_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_dd266_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_dd266_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_dd266_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_dd266_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row2\" class=\"row_heading level0 row2\" >generic</th>\n",
       "      <td id=\"T_dd266_row2_col0\" class=\"data row2 col0\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row2_col3\" class=\"data row2 col3\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row2_col4\" class=\"data row2 col4\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row2_col5\" class=\"data row2 col5\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row2_col6\" class=\"data row2 col6\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row2_col7\" class=\"data row2 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row3\" class=\"row_heading level0 row3\" >kool</th>\n",
       "      <td id=\"T_dd266_row3_col0\" class=\"data row3 col0\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "      <td id=\"T_dd266_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row3_col3\" class=\"data row3 col3\" >-0.0000</td>\n",
       "      <td id=\"T_dd266_row3_col4\" class=\"data row3 col4\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row3_col5\" class=\"data row3 col5\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row3_col6\" class=\"data row3 col6\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row3_col7\" class=\"data row3 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row4\" class=\"row_heading level0 row4\" >marlboro</th>\n",
       "      <td id=\"T_dd266_row4_col0\" class=\"data row4 col0\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "      <td id=\"T_dd266_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row4_col3\" class=\"data row4 col3\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row4_col4\" class=\"data row4 col4\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row4_col5\" class=\"data row4 col5\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row4_col6\" class=\"data row4 col6\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row4_col7\" class=\"data row4 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row5\" class=\"row_heading level0 row5\" >virginia slims</th>\n",
       "      <td id=\"T_dd266_row5_col0\" class=\"data row5 col0\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_dd266_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row5_col3\" class=\"data row5 col3\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row5_col4\" class=\"data row5 col4\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row5_col5\" class=\"data row5 col5\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row5_col6\" class=\"data row5 col6\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row5_col7\" class=\"data row5 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row6\" class=\"row_heading level0 row6\" >winston</th>\n",
       "      <td id=\"T_dd266_row6_col0\" class=\"data row6 col0\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row6_col1\" class=\"data row6 col1\" >nan</td>\n",
       "      <td id=\"T_dd266_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row6_col3\" class=\"data row6 col3\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row6_col4\" class=\"data row6 col4\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row6_col5\" class=\"data row6 col5\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row6_col6\" class=\"data row6 col6\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row6_col7\" class=\"data row6 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd266_level0_row7\" class=\"row_heading level0 row7\" >winston select</th>\n",
       "      <td id=\"T_dd266_row7_col0\" class=\"data row7 col0\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row7_col1\" class=\"data row7 col1\" >nan</td>\n",
       "      <td id=\"T_dd266_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row7_col3\" class=\"data row7 col3\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row7_col4\" class=\"data row7 col4\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row7_col5\" class=\"data row7 col5\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row7_col6\" class=\"data row7 col6\" >0.0000</td>\n",
       "      <td id=\"T_dd266_row7_col7\" class=\"data row7 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dd854a2ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# 4) Present Brand × Brand elasticities nicely\n",
    "# ========================\n",
    "alpha  = float(iv.params.get(\"price\", np.nan))\n",
    "beta_f = float(iv.params.get(\"flavored\", 0.0))   # 0 if not in Xnames\n",
    "\n",
    "df_calc = df2.loc[df2.index].copy()\n",
    "df_calc[\"brand_key\"] = brand_key.loc[df_calc.index].astype(\"string\")\n",
    "brands = sorted(list(df_calc[\"brand_key\"].unique()))\n",
    "\n",
    "E_price_sum={}; E_price_cnt={}; E_flav_sum={}; E_flav_cnt={}\n",
    "for b in brands:\n",
    "    for c in brands:\n",
    "        E_price_sum[(b,c)]=0.0; E_price_cnt[(b,c)]=0\n",
    "        E_flav_sum [(b,c)]=0.0; E_flav_cnt [(b,c)]=0\n",
    "\n",
    "for key, g in df_calc.groupby(mkt, observed=True):\n",
    "    s = g[\"prod_mkt_share\"].to_numpy()\n",
    "    p = g[\"price\"].to_numpy()\n",
    "    B = g[\"brand_key\"].to_numpy()\n",
    "    if s.size < 2: continue\n",
    "\n",
    "    Jp = alpha * (np.diag(s) - np.outer(s, s))\n",
    "    if \"flavored\" in g.columns:\n",
    "        f = g[\"flavored\"].to_numpy().astype(float)\n",
    "        Jf = beta_f * (np.diag(s * f) - np.outer(s, s * f))\n",
    "    else:\n",
    "        Jf = np.zeros((s.size, s.size))\n",
    "    JpP = Jp * p[None, :]  # % change\n",
    "\n",
    "    brands_here = np.unique(B)\n",
    "    S_b = {bk: float(s[B==bk].sum()) for bk in brands_here}\n",
    "\n",
    "    for b in brands_here:\n",
    "        Sb = S_b[b]\n",
    "        if Sb <= 0: continue\n",
    "        rows = (B == b)\n",
    "        rJpP = JpP[rows, :].sum(axis=0)\n",
    "        rJf  = Jf [rows, :].sum(axis=0)\n",
    "        for c in brands_here:\n",
    "            cols = (B == c)\n",
    "            E_bc_price = (rJpP[cols].sum()) / Sb\n",
    "            E_bc_flav  = - rJf[cols].sum()\n",
    "            E_price_sum[(b,c)] += E_bc_price; E_price_cnt[(b,c)] += 1\n",
    "            E_flav_sum [(b,c)] += E_bc_flav;  E_flav_cnt [(b,c)] += 1\n",
    "\n",
    "def avg_matrix(sum_d, cnt_d, brands):\n",
    "    M = np.full((len(brands), len(brands)), np.nan)\n",
    "    for i,b in enumerate(brands):\n",
    "        for j,c in enumerate(brands):\n",
    "            if cnt_d[(b,c)] > 0:\n",
    "                M[i,j] = sum_d[(b,c)] / cnt_d[(b,c)]\n",
    "    return pd.DataFrame(M, index=brands, columns=brands)\n",
    "    \n",
    "E_price = avg_matrix(E_price_sum, E_price_cnt, brands)  # %\n",
    "E_flav  = avg_matrix(E_flav_sum,  E_flav_cnt,  brands)  # share levels\n",
    "\n",
    "# 1) Ensure consistent brand order and build a % version for price\n",
    "brands = sorted(E_price.index.tolist())\n",
    "E_price = E_price.reindex(index=brands, columns=brands)\n",
    "E_flav  = E_flav .reindex(index=brands, columns=brands)\n",
    "E_price_pct = E_price \n",
    "E_price_pct = E_price_pct.fillna(0)\n",
    "\n",
    "# 2) Continuous (long/tidy) table — prints once without \"row-by-row\" updates\n",
    "elasticities_long = (\n",
    "    E_price_pct.stack().rename(\"price_elasticity_pct\")\n",
    "    .to_frame()\n",
    "    .join(E_flav.stack().rename(\"flavored_semi_delta\"))\n",
    "    .rename_axis(index=[\"affected_brand\",\"shocked_brand\"])\n",
    "    .reset_index()\n",
    "    .sort_values([\"affected_brand\",\"shocked_brand\"], kind=\"stable\")\n",
    ")\n",
    "\n",
    "# Pretty print in console\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_rows\", 100000)\n",
    "\"\"\"\n",
    "print(\"\\nBrand × Brand elasticities (continuous long format)\")\n",
    "print(elasticities_long.to_string(\n",
    "    index=False,\n",
    "    formatters={\n",
    "        \"price_elasticity_pct\": lambda v: f\"{v:8.3f}\",   # % ΔS_b for 1% ↑ price of brand c\n",
    "        \"flavored_semi_delta\":  lambda v: f\"{v: .5f}\",   # ΔS_b when brand c flavored is banned\n",
    "    }\n",
    "))\n",
    "\"\"\"\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    # price elasticities\n",
    "    display(\n",
    "        E_price_pct.style\n",
    "            .format(\"{:.2f}%\")\n",
    "            .background_gradient(cmap=\"coolwarm\", axis=None)\n",
    "            .set_caption(\"Brand × Brand PRICE Elasticities (% ΔS_b for 1% ↑ price of brand c)\")\n",
    "            .set_table_styles([\n",
    "                {\"selector\": \"th.col_heading\", \"props\": \"text-align:center;\"},\n",
    "                {\"selector\": \"th.row_heading\", \"props\": \"text-align:right;\"},\n",
    "            ])\n",
    "    )\n",
    "    # flavored semi-elasticities\n",
    "    display(\n",
    "        E_flav.style\n",
    "            .format(\"{:.4f}\")\n",
    "            .background_gradient(cmap=\"Greens\", axis=None)\n",
    "            .set_caption(\"Brand × Brand FLAVORED Semi-Elasticities (ΔS_b when brand c flavored is banned)\")\n",
    "            .set_table_styles([\n",
    "                {\"selector\": \"th.col_heading\", \"props\": \"text-align:center;\"},\n",
    "                {\"selector\": \"th.row_heading\", \"props\": \"text-align:right;\"},\n",
    "            ])\n",
    "    )\n",
    "except Exception:\n",
    "    # safe no-op if running outside a notebook\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4592f6-d416-4a73-a279-3d04485da70e",
   "metadata": {},
   "source": [
    "# Last ditch attempts at getting better elasticisties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05403160-8805-4701-b466-741ec170e066",
   "metadata": {},
   "source": [
    "## Aggregate quarterly instead of monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddb12fb5-9784-4a25-a78d-7b777ce5fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done.\n",
      "Final shape: (55690, 52)\n"
     ]
    }
   ],
   "source": [
    "########### 1: aggregate quarterly instead of monthly ##############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "final = pd.read_csv(\"cigarettes_monthly.csv\")\n",
    "\n",
    "base = int(final[\"month_idx\"].min())\n",
    "q_idx = ((final[\"month_idx\"] - base) // 3 + 1).astype(\"Int64\")   # running quarter index\n",
    "final[\"year_quarter\"] = \"Q\" + q_idx.astype(str)                  # simple label\n",
    "#final[\"year\"] = pd.NA\n",
    "final[\"quarter_id\"] = q_idx\n",
    "final[\"custcount\"] = final[\"custcount_monthly\"]\n",
    "final = final.drop('custcount_monthly', axis=1)\n",
    "\n",
    "known_dummies = [\n",
    "    \"menthol\",\"dlx\",\"special\",\"supslim\",\"slim\",\"generic\",\"single\",\"carton\",\"pack_kw\",\"value\",\n",
    "    \"generic_automated\",\"generic_hardcoded\",\"cigar\",\"snuff\",\"loose_tobacco\",\"flavored\",\"premium\",\n",
    "    \"cigarettes\",\"ok\",\"sale\"\n",
    "]\n",
    "dummy_cols = [c for c in known_dummies if c in final.columns]\n",
    "#for c in dummy_cols:\n",
    "#    final[c] = coerce_binary(final[c])\n",
    "\n",
    "#if isinstance(final.columns, pd.MultiIndex):\n",
    "#    final.columns = ['_'.join(map(str, c)).strip('_') for c in final.columns]\n",
    "\n",
    "known_continuous = [\n",
    "    \"tar_mean\",\"nic_mean\",\"co_mean\",\n",
    "    \"income\",\"educ\",\"hsizeavg\",\"age9\",\"age60\",\"ethnic\",\"nocar\"\n",
    "]\n",
    "if \"implied discount\" in final.columns:\n",
    "    known_continuous.append(\"implied discount\")\n",
    "\n",
    "cat_cols = [c for c in [\"brand\",\"size\",\"pack\"] if c in final.columns]\n",
    "\n",
    "time_cols = [\"month_idx\", \"year52\", \"m4\", \"month_label\"]\n",
    "\n",
    "group_cols = [\"store\", \"quarter_id\", \"prod_key\", \"prod_type\", \"prod_id\"] + [c for c in time_cols if c != \"month_idx\"]\n",
    "\n",
    "agg_dict = {\n",
    "    \"total_packs\": 'sum',\n",
    "    \"total_rev\": 'sum',\n",
    "    \"packs_per_item_wavg\": 'mean',\n",
    "    \"avg_pack_price\": 'mean',\n",
    "    \"custcount\": 'sum'}\n",
    "\n",
    "\n",
    "for c in dummy_cols:\n",
    "    agg_dict[c] = \"max\"\n",
    "for c in known_continuous:\n",
    "    agg_dict[c] = first_nonnull\n",
    "for c in cat_cols + [\"brand_clean\",\"upc_norm\"]:\n",
    "    if c in final.columns:\n",
    "        agg_dict[c] = first_nonnull\n",
    "    \n",
    "#agg_dict = {k:(k,v) for k,v in agg_dict.items()}\n",
    "\n",
    "quarterly = (\n",
    "    final.groupby(group_cols, as_index=False, observed=True)\n",
    "           .agg(agg_dict, numeric_only=False)\n",
    ")\n",
    "\n",
    "\n",
    "final[\"market_size_quarter\"] = 6.685 * final[\"custcount\"]*0.2325\n",
    "final[\"prod_mkt_share\"] = final[\"total_packs\"] / final[\"market_size_quarter\"]\n",
    "\n",
    "\n",
    "print(\"\\n✅ Done.\")\n",
    "print(\"Final shape:\", final.shape)\n",
    "\n",
    "quarterly.to_csv(\"cigarettes_quarterly.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "417ee18e-ed38-4e66-9c4f-165920a1e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OLS Nested Logit | Market FE absorbed]\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "price          -0.1143      0.026     -4.361      0.000      -0.166      -0.063\n",
      "ln_s_within     0.9270      0.003    286.288      0.000       0.921       0.933\n",
      "slim            0.3760      0.049      7.710      0.000       0.280       0.472\n",
      "value          -0.9105      0.059    -15.394      0.000      -1.026      -0.795\n",
      "premium         0.0860      0.011      7.731      0.000       0.064       0.108\n",
      "flavored       -0.1001      0.020     -5.026      0.000      -0.139      -0.061\n",
      "carton         -0.0027      0.018     -0.155      0.877      -0.037       0.032\n",
      "tar_mean        0.0917      0.015      6.071      0.000       0.062       0.121\n",
      "nic_mean       -1.8413      0.325     -5.666      0.000      -2.478      -1.204\n",
      "co_mean        -0.1350      0.019     -7.272      0.000      -0.171      -0.099\n",
      "===============================================================================\n",
      "\n",
      "[IV Nested Logit | Market FE absorbed | Hausman + BLP(cont) + Nest(cont)]\n",
      "\n",
      "σ (nesting): 0.091 | implied avg own-price elasticity ≈ 2.02\n"
     ]
    }
   ],
   "source": [
    "################## Rerun the code \n",
    "\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.iv import IV2SLS\n",
    "\n",
    "# -----------------------\n",
    "# helpers\n",
    "# -----------------------\n",
    "def series_flag(df, col, dtype=\"int8\"):\n",
    "    if col in df.columns:\n",
    "        return pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(dtype)\n",
    "    return pd.Series(0, index=df.index, dtype=dtype)\n",
    "\n",
    "def demean_within(frame, cols, keys):\n",
    "    means = frame.groupby(keys, observed=True)[cols].transform(\"mean\")\n",
    "    return frame[cols] - means\n",
    "\n",
    "def prune_instruments_for_full_rank(exog_df, Z_df, tol=1e-10):\n",
    "    W, keep = exog_df.copy(), []\n",
    "    for c in Z_df.columns:\n",
    "        r_old = np.linalg.matrix_rank(W.to_numpy(), tol)\n",
    "        W_try = pd.concat([W, Z_df[[c]]], axis=1)\n",
    "        r_new = np.linalg.matrix_rank(W_try.to_numpy(), tol)\n",
    "        if r_new > r_old:\n",
    "            keep.append(c); W = W_try\n",
    "    return Z_df[keep]\n",
    "\n",
    "def standardize_cols(df):\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        s = float(out[c].std(skipna=True))\n",
    "        if np.isfinite(s) and s > 0:\n",
    "            out[c] = out[c] / s\n",
    "    return out\n",
    "\n",
    "# ========================\n",
    "# 0) data & keys\n",
    "# ========================\n",
    "df = final.copy()\n",
    "df = df.rename(columns={\"avg_pack_price\": \"price\"})\n",
    "mkt = [\"store\",\"quarter_id\"]\n",
    "\n",
    "# inside/outside shares\n",
    "sum_inside = df.groupby(mkt, observed=True)[\"prod_mkt_share\"].transform(\"sum\")\n",
    "df = df[(df[\"prod_mkt_share\"] > 0) & (sum_inside < 1)].copy()\n",
    "df[\"s0\"] = np.clip(1.0 - sum_inside, 1e-12, 1 - 1e-12)\n",
    "\n",
    "# ids\n",
    "if \"prod_id\" not in df.columns:\n",
    "    if \"upc_norm\" in df.columns:\n",
    "        df[\"prod_id\"] = df[\"upc_norm\"].astype(\"string\")\n",
    "    elif \"upc\" in df.columns:\n",
    "        df[\"prod_id\"] = df[\"upc\"].astype(\"string\").str.replace(r\"\\D\",\"\", regex=True)\n",
    "    else:\n",
    "        df[\"prod_id\"] = df.index.astype(\"string\")\n",
    "\n",
    "# brand vs generic; nest = branded/generic\n",
    "brand_raw = df.get(\"brand\", pd.Series(\"\", index=df.index))\n",
    "brand_key = (brand_raw.astype(\"string\").str.strip().str.lower()\n",
    "             .mask(lambda s: s.eq(\"\") | s.isna(), \"generic\"))\n",
    "is_generic = (series_flag(df, \"generic_hardcoded\") > 0) | brand_key.eq(\"generic\")\n",
    "brand_key  = brand_key.mask(is_generic, \"generic\")\n",
    "df[\"nest\"] = np.where(brand_key.eq(\"generic\"), \"generic\", \"branded\")\n",
    "\n",
    "# ========================\n",
    "# 1) nested-logit shares (RAW)\n",
    "# ========================\n",
    "# ln s_j - ln s_0\n",
    "df[\"ln_s\"] = np.log(df[\"prod_mkt_share\"]) - np.log(df[\"s0\"])\n",
    "# within-nest share s_{j|g} and its log\n",
    "sg = df.groupby(mkt + [\"nest\"], observed=True)[\"prod_mkt_share\"].transform(\"sum\")\n",
    "df = df[sg > 0].copy()\n",
    "df[\"ln_s_within\"] = np.log(df[\"prod_mkt_share\"]) - np.log(sg)\n",
    "\n",
    "# regressors\n",
    "dummy_cols = [c for c in [\"dlx\",\"supslim\",\"slim\",\"value\",\"premium\",\"flavored\",\"carton\"] if c in df.columns]\n",
    "cont_cols  = [c for c in [\"tar_mean\",\"nic_mean\",\"co_mean\"] if c in df.columns]\n",
    "Xnames     = [\"price\",\"ln_s_within\"] + dummy_cols + cont_cols\n",
    "\n",
    "need = [\"ln_s\",\"price\",\"store\",\"quarter_id\",\"nest\",\"prod_id\"] + Xnames\n",
    "df2  = df.dropna(subset=need).copy()\n",
    "df2[\"brand_for_iv\"] = brand_key.loc[df2.index].astype(\"string\")\n",
    "\n",
    "# ========================\n",
    "# 2) instruments (RAW) – Hausman + BLP(cont) + Nest(cont)\n",
    "# ========================\n",
    "# --- Hausman (coalesced z1 -> z2 -> z3) ---\n",
    "g_uq = df2.groupby([\"prod_id\",\"quarter_id\"], observed=True)\n",
    "cnt_uq = g_uq[\"price\"].transform(\"count\"); sum_uq = g_uq[\"price\"].transform(\"sum\")\n",
    "z1_raw = np.where(cnt_uq.gt(1), (sum_uq - df2[\"price\"]) / (cnt_uq - 1), np.nan)\n",
    "\n",
    "g_u  = df2.groupby([\"prod_id\"], observed=True)\n",
    "cnt_u = g_u[\"price\"].transform(\"count\"); sum_u = g_u[\"price\"].transform(\"sum\")\n",
    "g_us = df2.groupby([\"prod_id\",\"store\"], observed=True)\n",
    "cnt_us = g_us[\"price\"].transform(\"count\"); sum_us = g_us[\"price\"].transform(\"sum\")\n",
    "z2_raw = np.where((cnt_u - cnt_us).gt(0), (sum_u - sum_us) / (cnt_u - cnt_us), np.nan)\n",
    "\n",
    "gbm  = df2.groupby([\"brand_for_iv\",\"quarter_id\"], observed=True)\n",
    "cnt_bm = gbm[\"price\"].transform(\"count\"); sum_bm = gbm[\"price\"].transform(\"sum\")\n",
    "gbms = df2.groupby([\"brand_for_iv\",\"quarter_id\",\"store\"], observed=True)\n",
    "cnt_bms = gbms[\"price\"].transform(\"count\"); sum_bms = gbms[\"price\"].transform(\"sum\")\n",
    "z3_raw = np.where((cnt_bm - cnt_bms).gt(0), (sum_bm - sum_bms) / (cnt_bm - cnt_bms), np.nan)\n",
    "\n",
    "z_haus_raw = pd.Series(z1_raw, index=df2.index)\n",
    "z_haus_raw = z_haus_raw.where(z_haus_raw.notna(), pd.Series(z2_raw, index=df2.index))\n",
    "z_haus_raw = z_haus_raw.where(z_haus_raw.notna(), pd.Series(z3_raw, index=df2.index))\n",
    "\n",
    "Z_raw = pd.DataFrame({\"z_haus\": z_haus_raw}, index=df2.index)\n",
    "\n",
    "# --- BLP(cont) by brand (as in simple logit) ---\n",
    "gm  = df2.groupby(mkt, observed=True)\n",
    "gfb = df2.groupby(mkt + [\"brand_for_iv\"], observed=True)\n",
    "for c in cont_cols:\n",
    "    tot = gm[c].transform(\"sum\")\n",
    "    own = gfb[c].transform(\"sum\")\n",
    "    Z_raw[f\"iv_brand_riv_sum_{c}\"] = tot - own\n",
    "    Z_raw[f\"iv_brand_own_sum_{c}\"] = own - df2[c]\n",
    "# rival count in market (helps 1st stage)\n",
    "Z_raw[\"iv_rival_count\"] = gm[\"price\"].transform(\"size\") - gfb[\"price\"].transform(\"size\")\n",
    "\n",
    "# --- Nest(cont) proxies for ln_s_within (same-nest & other-nest sums/counts) ---\n",
    "gmn = df2.groupby(mkt + [\"nest\"], observed=True)\n",
    "for c in cont_cols:\n",
    "    nest_tot = gmn[c].transform(\"sum\")\n",
    "    Z_raw[f\"iv_nest_same_sum_{c}\"]  = nest_tot - df2[c]\n",
    "    Z_raw[f\"iv_nest_other_sum_{c}\"] = gm[c].transform(\"sum\") - nest_tot\n",
    "# counts\n",
    "Z_raw[\"iv_nest_same_cnt\"]  = gmn[\"price\"].transform(\"size\") - 1\n",
    "Z_raw[\"iv_nest_other_cnt\"] = gm[\"price\"].transform(\"size\") - gmn[\"price\"].transform(\"size\")\n",
    "\n",
    "# ========================\n",
    "# 3) ONE FE removal for y, X, Z\n",
    "# ========================\n",
    "X_tilde = demean_within(df2, Xnames, mkt)\n",
    "y_tilde = (df2[\"ln_s\"] - df2.groupby(mkt, observed=True)[\"ln_s\"].transform(\"mean\")).rename(\"ln_s\")\n",
    "Z_tilde = demean_within(pd.concat([df2[mkt], Z_raw], axis=1), list(Z_raw.columns), mkt)\n",
    "\n",
    "# single estimation sample\n",
    "all_parts = pd.concat([y_tilde, X_tilde, Z_tilde], axis=1).replace([np.inf,-np.inf], np.nan).dropna()\n",
    "y_iv  = all_parts[\"ln_s\"]\n",
    "X_iv  = all_parts[Xnames]\n",
    "Z_iv  = all_parts[Z_tilde.columns]\n",
    "\n",
    "# drop zero-variance cols; standardize IVs; prune for rank\n",
    "X_iv = X_iv.loc[:, X_iv.apply(lambda s: np.nanstd(s.to_numpy()) > 0)]\n",
    "Z_iv = standardize_cols(Z_iv.loc[:, Z_iv.apply(lambda s: np.nanstd(s.to_numpy()) > 0)])\n",
    "\n",
    "# endogenous: price & ln_s_within\n",
    "exog  = X_iv.drop(columns=[\"price\",\"ln_s_within\"])\n",
    "Z_iv  = prune_instruments_for_full_rank(exog, Z_iv)\n",
    "\n",
    "clusters_iv = pd.to_numeric(df2.loc[all_parts.index, \"store\"], errors=\"coerce\").astype(int).to_numpy()\n",
    "\n",
    "# ========================\n",
    "# 4) Estimation\n",
    "# ========================\n",
    "ols = sm.OLS(y_iv, X_iv).fit(cov_type=\"cluster\", cov_kwds={\"groups\": clusters_iv})\n",
    "print(\"\\n[OLS Nested Logit | Market FE absorbed]\")\n",
    "print(ols.summary().tables[1])\n",
    "\n",
    "iv = IV2SLS(\n",
    "    dependent=y_iv,\n",
    "    exog=exog,\n",
    "    endog=X_iv[[\"price\",\"ln_s_within\"]],\n",
    "    instruments=Z_iv\n",
    ").fit(cov_type=\"clustered\", clusters=clusters_iv)\n",
    "print(\"\\n[IV Nested Logit | Market FE absorbed | Hausman + BLP(cont) + Nest(cont)]\")\n",
    "#print(iv.summary)\n",
    "#try:\n",
    "  #  print(\"\\n[First stages]\"); print(iv.first_stage.summary)\n",
    "#except:\n",
    "#    pass\n",
    "\n",
    "# quick elasticity diagnostic\n",
    "sigma = float(iv.params.get(\"ln_s_within\", np.nan))\n",
    "alpha = float(iv.params.get(\"price\", np.nan))\n",
    "sbar   = float(df2.loc[all_parts.index, \"prod_mkt_share\"].mean())\n",
    "sjgbar = float((df2.loc[all_parts.index, \"prod_mkt_share\"] /\n",
    "                df2.loc[all_parts.index].groupby(mkt + [\"nest\"], observed=True)[\"prod_mkt_share\"].transform(\"sum\")).mean())\n",
    "pbar   = float(df2.loc[all_parts.index, \"price\"].mean())\n",
    "eps    = -alpha * pbar * (1 - sigma*(1 - sjgbar) - sbar)\n",
    "print(f\"\\nσ (nesting): {sigma:.3f} | implied avg own-price elasticity ≈ {eps:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b2bf7d5-87d3-4785-b842-9ecf224a5ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3c7fe_ th.col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_3c7fe_ th.row_heading {\n",
       "  text-align: right;\n",
       "}\n",
       "#T_3c7fe_row0_col0 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3c7fe_row0_col1, #T_3c7fe_row0_col3, #T_3c7fe_row0_col5, #T_3c7fe_row0_col6, #T_3c7fe_row0_col7, #T_3c7fe_row1_col0, #T_3c7fe_row1_col3, #T_3c7fe_row1_col4, #T_3c7fe_row1_col5, #T_3c7fe_row1_col6, #T_3c7fe_row1_col7, #T_3c7fe_row2_col0, #T_3c7fe_row2_col1, #T_3c7fe_row2_col3, #T_3c7fe_row2_col5, #T_3c7fe_row2_col6, #T_3c7fe_row2_col7, #T_3c7fe_row3_col0, #T_3c7fe_row3_col1, #T_3c7fe_row3_col5, #T_3c7fe_row3_col6, #T_3c7fe_row3_col7, #T_3c7fe_row4_col0, #T_3c7fe_row4_col1, #T_3c7fe_row4_col3, #T_3c7fe_row4_col5, #T_3c7fe_row4_col6, #T_3c7fe_row4_col7, #T_3c7fe_row5_col0, #T_3c7fe_row5_col1, #T_3c7fe_row5_col3, #T_3c7fe_row5_col6, #T_3c7fe_row5_col7, #T_3c7fe_row6_col0, #T_3c7fe_row6_col1, #T_3c7fe_row6_col3, #T_3c7fe_row6_col5, #T_3c7fe_row6_col7, #T_3c7fe_row7_col0, #T_3c7fe_row7_col1, #T_3c7fe_row7_col3, #T_3c7fe_row7_col5, #T_3c7fe_row7_col6 {\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3c7fe_row0_col2, #T_3c7fe_row1_col2, #T_3c7fe_row3_col2, #T_3c7fe_row4_col2, #T_3c7fe_row5_col2, #T_3c7fe_row6_col2, #T_3c7fe_row7_col2, #T_3c7fe_row7_col4 {\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3c7fe_row0_col4, #T_3c7fe_row2_col4, #T_3c7fe_row3_col4, #T_3c7fe_row5_col4, #T_3c7fe_row6_col4 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3c7fe_row1_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3c7fe_row2_col2 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3c7fe_row3_col3 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3c7fe_row4_col4 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3c7fe_row5_col5 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3c7fe_row6_col6 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3c7fe_row7_col7 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3c7fe_\">\n",
       "  <caption>Brand × Brand PRICE Elasticities (% ΔS_b for 1% ↑ price of brand c)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >benson & hedges</th>\n",
       "      <th class=\"col_heading level0 col1\" >doral</th>\n",
       "      <th class=\"col_heading level0 col2\" >generic</th>\n",
       "      <th class=\"col_heading level0 col3\" >kool</th>\n",
       "      <th class=\"col_heading level0 col4\" >marlboro</th>\n",
       "      <th class=\"col_heading level0 col5\" >virginia slims</th>\n",
       "      <th class=\"col_heading level0 col6\" >winston</th>\n",
       "      <th class=\"col_heading level0 col7\" >winston select</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row0\" class=\"row_heading level0 row0\" >benson & hedges</th>\n",
       "      <td id=\"T_3c7fe_row0_col0\" class=\"data row0 col0\" >-2.24%</td>\n",
       "      <td id=\"T_3c7fe_row0_col1\" class=\"data row0 col1\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row0_col2\" class=\"data row0 col2\" >0.02%</td>\n",
       "      <td id=\"T_3c7fe_row0_col3\" class=\"data row0 col3\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row0_col4\" class=\"data row0 col4\" >0.03%</td>\n",
       "      <td id=\"T_3c7fe_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row0_col6\" class=\"data row0 col6\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row0_col7\" class=\"data row0 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row1\" class=\"row_heading level0 row1\" >doral</th>\n",
       "      <td id=\"T_3c7fe_row1_col0\" class=\"data row1 col0\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row1_col1\" class=\"data row1 col1\" >-3.87%</td>\n",
       "      <td id=\"T_3c7fe_row1_col2\" class=\"data row1 col2\" >0.02%</td>\n",
       "      <td id=\"T_3c7fe_row1_col3\" class=\"data row1 col3\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row1_col4\" class=\"data row1 col4\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row1_col6\" class=\"data row1 col6\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row1_col7\" class=\"data row1 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row2\" class=\"row_heading level0 row2\" >generic</th>\n",
       "      <td id=\"T_3c7fe_row2_col0\" class=\"data row2 col0\" >0.01%</td>\n",
       "      <td id=\"T_3c7fe_row2_col1\" class=\"data row2 col1\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row2_col2\" class=\"data row2 col2\" >-2.07%</td>\n",
       "      <td id=\"T_3c7fe_row2_col3\" class=\"data row2 col3\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row2_col4\" class=\"data row2 col4\" >0.03%</td>\n",
       "      <td id=\"T_3c7fe_row2_col5\" class=\"data row2 col5\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row2_col6\" class=\"data row2 col6\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row2_col7\" class=\"data row2 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row3\" class=\"row_heading level0 row3\" >kool</th>\n",
       "      <td id=\"T_3c7fe_row3_col0\" class=\"data row3 col0\" >0.01%</td>\n",
       "      <td id=\"T_3c7fe_row3_col1\" class=\"data row3 col1\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row3_col2\" class=\"data row3 col2\" >0.02%</td>\n",
       "      <td id=\"T_3c7fe_row3_col3\" class=\"data row3 col3\" >-2.35%</td>\n",
       "      <td id=\"T_3c7fe_row3_col4\" class=\"data row3 col4\" >0.03%</td>\n",
       "      <td id=\"T_3c7fe_row3_col5\" class=\"data row3 col5\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row3_col6\" class=\"data row3 col6\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row3_col7\" class=\"data row3 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row4\" class=\"row_heading level0 row4\" >marlboro</th>\n",
       "      <td id=\"T_3c7fe_row4_col0\" class=\"data row4 col0\" >0.01%</td>\n",
       "      <td id=\"T_3c7fe_row4_col1\" class=\"data row4 col1\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row4_col2\" class=\"data row4 col2\" >0.02%</td>\n",
       "      <td id=\"T_3c7fe_row4_col3\" class=\"data row4 col3\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row4_col4\" class=\"data row4 col4\" >-2.30%</td>\n",
       "      <td id=\"T_3c7fe_row4_col5\" class=\"data row4 col5\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row4_col6\" class=\"data row4 col6\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row4_col7\" class=\"data row4 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row5\" class=\"row_heading level0 row5\" >virginia slims</th>\n",
       "      <td id=\"T_3c7fe_row5_col0\" class=\"data row5 col0\" >0.01%</td>\n",
       "      <td id=\"T_3c7fe_row5_col1\" class=\"data row5 col1\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row5_col2\" class=\"data row5 col2\" >0.02%</td>\n",
       "      <td id=\"T_3c7fe_row5_col3\" class=\"data row5 col3\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row5_col4\" class=\"data row5 col4\" >0.03%</td>\n",
       "      <td id=\"T_3c7fe_row5_col5\" class=\"data row5 col5\" >-2.25%</td>\n",
       "      <td id=\"T_3c7fe_row5_col6\" class=\"data row5 col6\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row5_col7\" class=\"data row5 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row6\" class=\"row_heading level0 row6\" >winston</th>\n",
       "      <td id=\"T_3c7fe_row6_col0\" class=\"data row6 col0\" >0.01%</td>\n",
       "      <td id=\"T_3c7fe_row6_col1\" class=\"data row6 col1\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row6_col2\" class=\"data row6 col2\" >0.01%</td>\n",
       "      <td id=\"T_3c7fe_row6_col3\" class=\"data row6 col3\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row6_col4\" class=\"data row6 col4\" >0.04%</td>\n",
       "      <td id=\"T_3c7fe_row6_col5\" class=\"data row6 col5\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row6_col6\" class=\"data row6 col6\" >-1.44%</td>\n",
       "      <td id=\"T_3c7fe_row6_col7\" class=\"data row6 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c7fe_level0_row7\" class=\"row_heading level0 row7\" >winston select</th>\n",
       "      <td id=\"T_3c7fe_row7_col0\" class=\"data row7 col0\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row7_col1\" class=\"data row7 col1\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row7_col2\" class=\"data row7 col2\" >0.02%</td>\n",
       "      <td id=\"T_3c7fe_row7_col3\" class=\"data row7 col3\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row7_col4\" class=\"data row7 col4\" >0.02%</td>\n",
       "      <td id=\"T_3c7fe_row7_col5\" class=\"data row7 col5\" >0.00%</td>\n",
       "      <td id=\"T_3c7fe_row7_col6\" class=\"data row7 col6\" >0.01%</td>\n",
       "      <td id=\"T_3c7fe_row7_col7\" class=\"data row7 col7\" >-1.91%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dd893616d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ba1a8_ th.col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_ba1a8_ th.row_heading {\n",
       "  text-align: right;\n",
       "}\n",
       "#T_ba1a8_row0_col0, #T_ba1a8_row0_col1, #T_ba1a8_row1_col0, #T_ba1a8_row1_col3, #T_ba1a8_row1_col4, #T_ba1a8_row1_col5, #T_ba1a8_row1_col7, #T_ba1a8_row3_col1, #T_ba1a8_row4_col1, #T_ba1a8_row5_col1, #T_ba1a8_row7_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ba1a8_row0_col2, #T_ba1a8_row0_col3, #T_ba1a8_row0_col4, #T_ba1a8_row0_col5, #T_ba1a8_row0_col6, #T_ba1a8_row0_col7, #T_ba1a8_row1_col2, #T_ba1a8_row1_col6, #T_ba1a8_row2_col1, #T_ba1a8_row2_col2, #T_ba1a8_row2_col4, #T_ba1a8_row2_col5, #T_ba1a8_row2_col6, #T_ba1a8_row2_col7, #T_ba1a8_row3_col0, #T_ba1a8_row3_col2, #T_ba1a8_row3_col4, #T_ba1a8_row3_col5, #T_ba1a8_row3_col6, #T_ba1a8_row3_col7, #T_ba1a8_row4_col2, #T_ba1a8_row4_col4, #T_ba1a8_row4_col5, #T_ba1a8_row4_col6, #T_ba1a8_row4_col7, #T_ba1a8_row5_col0, #T_ba1a8_row5_col2, #T_ba1a8_row5_col3, #T_ba1a8_row5_col4, #T_ba1a8_row5_col5, #T_ba1a8_row5_col6, #T_ba1a8_row5_col7, #T_ba1a8_row6_col0, #T_ba1a8_row6_col1, #T_ba1a8_row6_col2, #T_ba1a8_row6_col3, #T_ba1a8_row6_col4, #T_ba1a8_row6_col5, #T_ba1a8_row6_col6, #T_ba1a8_row6_col7, #T_ba1a8_row7_col0, #T_ba1a8_row7_col2, #T_ba1a8_row7_col3, #T_ba1a8_row7_col4, #T_ba1a8_row7_col5, #T_ba1a8_row7_col6, #T_ba1a8_row7_col7 {\n",
       "  background-color: #00491d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba1a8_row1_col1 {\n",
       "  background-color: #005522;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba1a8_row2_col0 {\n",
       "  background-color: #00471c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba1a8_row2_col3 {\n",
       "  background-color: #00481d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba1a8_row3_col3 {\n",
       "  background-color: #acdea6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ba1a8_row4_col0 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba1a8_row4_col3 {\n",
       "  background-color: #00451c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ba1a8_\">\n",
       "  <caption>Brand × Brand FLAVORED Semi-Elasticities (ΔS_b when brand c flavored is banned)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >benson & hedges</th>\n",
       "      <th class=\"col_heading level0 col1\" >doral</th>\n",
       "      <th class=\"col_heading level0 col2\" >generic</th>\n",
       "      <th class=\"col_heading level0 col3\" >kool</th>\n",
       "      <th class=\"col_heading level0 col4\" >marlboro</th>\n",
       "      <th class=\"col_heading level0 col5\" >virginia slims</th>\n",
       "      <th class=\"col_heading level0 col6\" >winston</th>\n",
       "      <th class=\"col_heading level0 col7\" >winston select</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row0\" class=\"row_heading level0 row0\" >benson & hedges</th>\n",
       "      <td id=\"T_ba1a8_row0_col0\" class=\"data row0 col0\" >-0.0003</td>\n",
       "      <td id=\"T_ba1a8_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row0_col3\" class=\"data row0 col3\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row0_col5\" class=\"data row0 col5\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row1\" class=\"row_heading level0 row1\" >doral</th>\n",
       "      <td id=\"T_ba1a8_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row1_col1\" class=\"data row1 col1\" >-0.0000</td>\n",
       "      <td id=\"T_ba1a8_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row1_col6\" class=\"data row1 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row2\" class=\"row_heading level0 row2\" >generic</th>\n",
       "      <td id=\"T_ba1a8_row2_col0\" class=\"data row2 col0\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row2_col3\" class=\"data row2 col3\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row2_col4\" class=\"data row2 col4\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row2_col5\" class=\"data row2 col5\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row2_col6\" class=\"data row2 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row2_col7\" class=\"data row2 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row3\" class=\"row_heading level0 row3\" >kool</th>\n",
       "      <td id=\"T_ba1a8_row3_col0\" class=\"data row3 col0\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row3_col3\" class=\"data row3 col3\" >-0.0002</td>\n",
       "      <td id=\"T_ba1a8_row3_col4\" class=\"data row3 col4\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row3_col5\" class=\"data row3 col5\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row3_col6\" class=\"data row3 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row3_col7\" class=\"data row3 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row4\" class=\"row_heading level0 row4\" >marlboro</th>\n",
       "      <td id=\"T_ba1a8_row4_col0\" class=\"data row4 col0\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row4_col3\" class=\"data row4 col3\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row4_col4\" class=\"data row4 col4\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row4_col5\" class=\"data row4 col5\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row4_col6\" class=\"data row4 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row4_col7\" class=\"data row4 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row5\" class=\"row_heading level0 row5\" >virginia slims</th>\n",
       "      <td id=\"T_ba1a8_row5_col0\" class=\"data row5 col0\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row5_col3\" class=\"data row5 col3\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row5_col4\" class=\"data row5 col4\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row5_col5\" class=\"data row5 col5\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row5_col6\" class=\"data row5 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row5_col7\" class=\"data row5 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row6\" class=\"row_heading level0 row6\" >winston</th>\n",
       "      <td id=\"T_ba1a8_row6_col0\" class=\"data row6 col0\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row6_col1\" class=\"data row6 col1\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row6_col3\" class=\"data row6 col3\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row6_col4\" class=\"data row6 col4\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row6_col5\" class=\"data row6 col5\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row6_col6\" class=\"data row6 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row6_col7\" class=\"data row6 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba1a8_level0_row7\" class=\"row_heading level0 row7\" >winston select</th>\n",
       "      <td id=\"T_ba1a8_row7_col0\" class=\"data row7 col0\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row7_col1\" class=\"data row7 col1\" >nan</td>\n",
       "      <td id=\"T_ba1a8_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row7_col3\" class=\"data row7 col3\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row7_col4\" class=\"data row7 col4\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row7_col5\" class=\"data row7 col5\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row7_col6\" class=\"data row7 col6\" >0.0000</td>\n",
       "      <td id=\"T_ba1a8_row7_col7\" class=\"data row7 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dd893616d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha  = float(iv.params.get(\"price\", np.nan))\n",
    "beta_f = float(iv.params.get(\"flavored\", 0.0))   # 0 if not in Xnames\n",
    "\n",
    "df_calc = df2.loc[df2.index].copy()\n",
    "df_calc[\"brand_key\"] = brand_key.loc[df_calc.index].astype(\"string\")\n",
    "brands = sorted(list(df_calc[\"brand_key\"].unique()))\n",
    "\n",
    "E_price_sum={}; E_price_cnt={}; E_flav_sum={}; E_flav_cnt={}\n",
    "for b in brands:\n",
    "    for c in brands:\n",
    "        E_price_sum[(b,c)]=0.0; E_price_cnt[(b,c)]=0\n",
    "        E_flav_sum [(b,c)]=0.0; E_flav_cnt [(b,c)]=0\n",
    "\n",
    "for key, g in df_calc.groupby(mkt, observed=True):\n",
    "    s = g[\"prod_mkt_share\"].to_numpy()\n",
    "    p = g[\"price\"].to_numpy()\n",
    "    B = g[\"brand_key\"].to_numpy()\n",
    "    if s.size < 2: continue\n",
    "\n",
    "    Jp = alpha * (np.diag(s) - np.outer(s, s))\n",
    "    if \"flavored\" in g.columns:\n",
    "        f = g[\"flavored\"].to_numpy().astype(float)\n",
    "        Jf = beta_f * (np.diag(s * f) - np.outer(s, s * f))\n",
    "    else:\n",
    "        Jf = np.zeros((s.size, s.size))\n",
    "    JpP = Jp * p[None, :]  # % change\n",
    "\n",
    "    brands_here = np.unique(B)\n",
    "    S_b = {bk: float(s[B==bk].sum()) for bk in brands_here}\n",
    "\n",
    "    for b in brands_here:\n",
    "        Sb = S_b[b]\n",
    "        if Sb <= 0: continue\n",
    "        rows = (B == b)\n",
    "        rJpP = JpP[rows, :].sum(axis=0)\n",
    "        rJf  = Jf [rows, :].sum(axis=0)\n",
    "        for c in brands_here:\n",
    "            cols = (B == c)\n",
    "            E_bc_price = (rJpP[cols].sum()) / Sb\n",
    "            E_bc_flav  = - rJf[cols].sum()\n",
    "            E_price_sum[(b,c)] += E_bc_price; E_price_cnt[(b,c)] += 1\n",
    "            E_flav_sum [(b,c)] += E_bc_flav;  E_flav_cnt [(b,c)] += 1\n",
    "\n",
    "def avg_matrix(sum_d, cnt_d, brands):\n",
    "    M = np.full((len(brands), len(brands)), np.nan)\n",
    "    for i,b in enumerate(brands):\n",
    "        for j,c in enumerate(brands):\n",
    "            if cnt_d[(b,c)] > 0:\n",
    "                M[i,j] = sum_d[(b,c)] / cnt_d[(b,c)]\n",
    "    return pd.DataFrame(M, index=brands, columns=brands)\n",
    "    \n",
    "E_price = avg_matrix(E_price_sum, E_price_cnt, brands)  # %\n",
    "E_flav  = avg_matrix(E_flav_sum,  E_flav_cnt,  brands)  # share levels\n",
    "\n",
    "# 1) Ensure consistent brand order and build a % version for price\n",
    "brands = sorted(E_price.index.tolist())\n",
    "E_price = E_price.reindex(index=brands, columns=brands)\n",
    "E_flav  = E_flav .reindex(index=brands, columns=brands)\n",
    "E_price_pct = E_price \n",
    "E_price_pct = E_price_pct.fillna(0)\n",
    "\n",
    "# 2) Continuous (long/tidy) table — prints once without \"row-by-row\" updates\n",
    "elasticities_long = (\n",
    "    E_price_pct.stack().rename(\"price_elasticity_pct\")\n",
    "    .to_frame()\n",
    "    .join(E_flav.stack().rename(\"flavored_semi_delta\"))\n",
    "    .rename_axis(index=[\"affected_brand\",\"shocked_brand\"])\n",
    "    .reset_index()\n",
    "    .sort_values([\"affected_brand\",\"shocked_brand\"], kind=\"stable\")\n",
    ")\n",
    "\n",
    "# Pretty print in console\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_rows\", 100000)\n",
    "\"\"\"\n",
    "print(\"\\nBrand × Brand elasticities (continuous long format)\")\n",
    "print(elasticities_long.to_string(\n",
    "    index=False,\n",
    "    formatters={\n",
    "        \"price_elasticity_pct\": lambda v: f\"{v:8.3f}\",   # % ΔS_b for 1% ↑ price of brand c\n",
    "        \"flavored_semi_delta\":  lambda v: f\"{v: .5f}\",   # ΔS_b when brand c flavored is banned\n",
    "    }\n",
    "))\n",
    "\"\"\"\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    # price elasticities\n",
    "    display(\n",
    "        E_price_pct.style\n",
    "            .format(\"{:.2f}%\")\n",
    "            .background_gradient(cmap=\"coolwarm\", axis=None)\n",
    "            .set_caption(\"Brand × Brand PRICE Elasticities (% ΔS_b for 1% ↑ price of brand c)\")\n",
    "            .set_table_styles([\n",
    "                {\"selector\": \"th.col_heading\", \"props\": \"text-align:center;\"},\n",
    "                {\"selector\": \"th.row_heading\", \"props\": \"text-align:right;\"},\n",
    "            ])\n",
    "    )\n",
    "    # flavored semi-elasticities\n",
    "    display(\n",
    "        E_flav.style\n",
    "            .format(\"{:.4f}\")\n",
    "            .background_gradient(cmap=\"Greens\", axis=None)\n",
    "            .set_caption(\"Brand × Brand FLAVORED Semi-Elasticities (ΔS_b when brand c flavored is banned)\")\n",
    "            .set_table_styles([\n",
    "                {\"selector\": \"th.col_heading\", \"props\": \"text-align:center;\"},\n",
    "                {\"selector\": \"th.row_heading\", \"props\": \"text-align:right;\"},\n",
    "            ])\n",
    "    )\n",
    "except Exception:\n",
    "    # safe no-op if running outside a notebook\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bffd57d-377d-4472-9d8d-7768ddf7b232",
   "metadata": {},
   "source": [
    "## Incorporate wholesale prices from Maxwell report \n",
    "https://www.industrydocuments.ucsf.edu/tobacco/documents/viewer/?iid=kzkx0049&id=kzkx0049&q=q%3Dnull%2Call%2Ccontains%2Cbox%3A%221125%22&db-set=documents&industry=tobacco&sort=relevance&pg=1&npp=20&rtool=metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890b8750-a52c-42db-937b-b873a5db0718",
   "metadata": {},
   "source": [
    "The OCR the did not pan out :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ddab6-a7eb-4eb3-b81c-c52f8b02f17e",
   "metadata": {},
   "source": [
    "# Counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570c6c7-0a4c-441d-8612-9657fc543048",
   "metadata": {},
   "source": [
    "In the first counterfactual, the tax does *not* get raised to 44c in 1993, and thus cigs are 14c cheaper. In the second counterfactual, the Illinois government is as paternalistic (revenue-hungry?) as their neighbors in Michigan, and sets the tax rate at 75c. We count govt revenue and social surplus separatedly. \n",
    "\n",
    "Social cost\" refers to a quantification of the externality/tax burden created by a smoker. This varies from state to state depending on local conditions (eg welfare, employment, avg age). We do not have data for 1990, but according to a study conducted in 2018, the difference between the social cost of an active smoker and those of a former smoker was 2986$/yr in 2018 dollars, or 1,810.63/yr in 1995 dollars. \n",
    "\n",
    "We want to notice that 1. the study only counts productivity losses associated with smoking, the actual welfare loss is necessarily much higher 2. Both the quantity consumed by the average smoker, and the tolerance for smoking in public places, has declined significantly since 2018. Thus this recent estimation is likely very conservative and provides a lower-bound for the social surplus. \n",
    "\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC10108669/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1d8f47bd-5b29-43ba-aed0-b5c47a54a463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store', 'month_idx', 'prod_key', 'prod_type', 'prod_id', 'year52', 'm4', 'month_label', 'total_packs', 'total_rev', 'packs_per_item_wavg', 'price',\n",
       "       'menthol', 'dlx', 'special', 'supslim', 'slim', 'single', 'carton', 'pack_kw', 'value', 'generic_automated', 'generic_hardcoded', 'cigar', 'snuff',\n",
       "       'flavored', 'premium', 'cigarettes', 'ok', 'sale', 'tar_mean', 'nic_mean', 'co_mean', 'income', 'educ', 'hsizeavg', 'age9', 'age60', 'ethnic', 'nocar',\n",
       "       'implied discount', 'brand', 'size', 'pack', 'brand_clean', 'upc_norm', 'market_size_month', 'prod_mkt_share', 'year_quarter', 'quarter_id',\n",
       "       'custcount', 'market_size_quarter', 's0', 'nest', 'ln_s', 'ln_s_within'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6480b191-affe-4793-92bb-729a91a63aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-market summary (first rows):\n",
      "   store  quarter_id   CS_base    CS_new       dCS  s0_base_pred  s0_new_pred  delta_outside  market_size_used\n",
      "0      2           1  0.039945  0.025569 -0.014376      0.964482     0.977117       0.012635     130056.541300\n",
      "1      2           2  0.027723  0.017710 -0.010013      0.975214     0.984094       0.008880     723371.352870\n",
      "2      2           3  0.036980  0.023659 -0.013320      0.967075     0.978808       0.011733     107830.291500\n",
      "3      2           4  0.024935  0.015922 -0.009013      0.977679     0.985689       0.008010     677430.358277\n",
      "4      2           5  0.018595  0.011861 -0.006734      0.983307     0.989319       0.006013     615094.484748\n",
      "\n",
      "Totals:\n",
      "{'total_dCS': -7988221.85213534, 'total_delta_outside': 12.480918828988365, 'note': 'Weighted by provided market sizes'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Inputs expected in df2 (your estimation sample):\n",
    "# - keys: [\"store\",\"quarter_id\",\"nest\",\"prod_id\"]\n",
    "# - baseline cols: \"prod_mkt_share\" (s_j), \"s0\", \"price\"\n",
    "# Optional:\n",
    "# - market size column, e.g. \"market_size\" (units of potential consumers or total quantity base)\n",
    "# - counterfactual prices in \"price_cf\"\n",
    "# If \"price_cf\" is missing, you can pass a scalar tax or a dict of deltas to the function.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def simulate_nested_welfare(\n",
    "    df2,\n",
    "    alpha,                 # price coefficient (negative)\n",
    "    sigma,                 # nesting (0 < sigma < 1)\n",
    "    *,\n",
    "    tax_scalar=None,       # e.g., +0.50 (add-on to all prices); mutually exclusive with price_delta_map\n",
    "    price_delta_map=None,  # dict {prod_id: Δp} to add product-specific deltas\n",
    "    price_cf_col=\"price_cf\",\n",
    "    market_keys=(\"store\",\"quarter_id\"),\n",
    "    market_size_col=\"market_size_quarter\"   # if provided, Δ outside *units* is returned; else Δ outside share\n",
    "):\n",
    "    if not (0 < sigma < 1):\n",
    "        raise ValueError(\"sigma should be in (0,1) for nested logit aggregation.\")\n",
    "    one_minus_sigma = 1.0 - sigma\n",
    "\n",
    "    # Work copy\n",
    "    d = df2.copy()\n",
    "\n",
    "    # Ensure required logs exist (recompute robustly)\n",
    "    # ln s_j - ln s_0\n",
    "    d[\"ln_s\"] = np.log(np.clip(d[\"prod_mkt_share\"], 1e-15, 1)) - np.log(np.clip(d[\"s0\"], 1e-15, 1))\n",
    "    # ln s_{j|g} = ln s_j - ln (sum_{k in g} s_k)\n",
    "    sg = d.groupby(list(market_keys)+[\"nest\"], observed=True)[\"prod_mkt_share\"].transform(\"sum\")\n",
    "    d = d[sg > 0].copy()\n",
    "    d[\"ln_s_within\"] = np.log(np.clip(d[\"prod_mkt_share\"], 1e-15, 1)) - np.log(np.clip(sg, 1e-15, 1))\n",
    "\n",
    "    # Invert baseline mean utility δ_hat from shares: δ_j = (ln s_j - ln s_0) - sigma * ln s_{j|g}\n",
    "    d[\"delta_base\"] = d[\"ln_s\"] - sigma * d[\"ln_s_within\"]\n",
    "\n",
    "    # Build counterfactual prices\n",
    "    p_new = d[\"price\"].astype(float).copy()\n",
    "    if price_cf_col in d.columns:\n",
    "        p_new = d[price_cf_col].astype(float)\n",
    "    else:\n",
    "        if tax_scalar is not None:\n",
    "            p_new = p_new + float(tax_scalar)\n",
    "        if price_delta_map is not None:\n",
    "            # add product-specific deltas where provided\n",
    "            idxer = d[\"prod_id\"].map(price_delta_map).fillna(0.0).astype(float)\n",
    "            p_new = p_new + idxer\n",
    "\n",
    "    # Counterfactual δ: δ_new = δ_base - α * (p_new - p_base)\n",
    "    d[\"delta_new\"] = d[\"delta_base\"] + alpha * (p_new - d[\"price\"].astype(float))\n",
    "    # Helper to compute nested-logit shares from δ within each market:\n",
    "    def nl_shares_for_market(frame):\n",
    "        # frame has rows for a single market with columns: nest, delta_base, delta_new\n",
    "        out = frame.copy()\n",
    "\n",
    "        def shares_from_delta(colname):\n",
    "            # D_g = sum_{j in g} exp( δ_j / (1-σ) )\n",
    "            ex = np.exp(out[colname] / one_minus_sigma)\n",
    "            Dg = ex.groupby(out[\"nest\"]).transform(\"sum\")\n",
    "            # Group mass S_g = D_g^{1-σ} / (1 + sum_h D_h^{1-σ})\n",
    "            Dg_group = ex.groupby(out[\"nest\"]).sum()\n",
    "            group_mass = (Dg_group ** one_minus_sigma).sum()\n",
    "            s0 = 1.0 / (1.0 + group_mass)\n",
    "            Sg = (Dg ** one_minus_sigma) * s0  # broadcast S_g to rows via Dg\n",
    "\n",
    "            # Within-nest share s_{j|g} = exp(δ/(1-σ)) / D_g\n",
    "            sj_given_g = ex / Dg\n",
    "\n",
    "            # Product share: s_j = s_{j|g} * S_g\n",
    "            sj = sj_given_g * Sg\n",
    "            return sj, s0\n",
    "\n",
    "        sj_base, s0_base = shares_from_delta(\"delta_base\")\n",
    "        sj_new,  s0_new  = shares_from_delta(\"delta_new\")\n",
    "\n",
    "        out[\"s_base_pred\"] = sj_base\n",
    "        out[\"s_new_pred\"]  = sj_new\n",
    "        # attach s0 once per market (duplicate per row for convenience)\n",
    "        out[\"s0_base_pred\"] = s0_base\n",
    "        out[\"s0_new_pred\"]  = s0_new\n",
    "        return out\n",
    "\n",
    "    # Apply per market\n",
    "    d = d.groupby(list(market_keys), observed=True, group_keys=False).apply(nl_shares_for_market)\n",
    "\n",
    "    # Consumer surplus per market (per consumer):\n",
    "    # CS = (1/(-alpha)) * ln( 1 + sum_g [ sum_{j in g} exp(δ_j/(1-σ)) ]^{1-σ} )\n",
    "    def cs_from_delta(frame, colname):\n",
    "        ex = np.exp(frame[colname] / one_minus_sigma)\n",
    "        Dg = ex.groupby(frame[\"nest\"]).sum()\n",
    "        logsum = np.log(1.0 + np.power(Dg, one_minus_sigma).sum())\n",
    "        return float(logsum / (-alpha))\n",
    "\n",
    "    cs_rows = []\n",
    "    for mk, g in d.groupby(list(market_keys), observed=True):\n",
    "        cs_base = cs_from_delta(g, \"delta_base\")\n",
    "        cs_new  = cs_from_delta(g, \"delta_new\")\n",
    "        s0_b    = float(g[\"s0_base_pred\"].iloc[0])\n",
    "        s0_n    = float(g[\"s0_new_pred\"].iloc[0])\n",
    "\n",
    "        # Δ outside option (units if market_size_col provided, else share)\n",
    "        if (market_size_col is not None) and (market_size_col in g.columns):\n",
    "            M = float(g[market_size_col].iloc[0])\n",
    "            delta_outside_units = (s0_n - s0_b) * M\n",
    "        else:\n",
    "            M = np.nan\n",
    "            delta_outside_units = (s0_n - s0_b)  # share-point change\n",
    "\n",
    "        cs_rows.append({\n",
    "            **{k:v for k,v in zip(market_keys, mk if isinstance(mk, tuple) else (mk,))},\n",
    "            \"CS_base\": cs_base,\n",
    "            \"CS_new\": cs_new,\n",
    "            \"dCS\": cs_new - cs_base,\n",
    "            \"s0_base_pred\": s0_b,\n",
    "            \"s0_new_pred\": s0_n,\n",
    "            \"delta_outside\": s0_n - s0_b,\n",
    "            \"market_size_used\": M\n",
    "        })\n",
    "    market_summary = pd.DataFrame(cs_rows)\n",
    "\n",
    "    # Totals\n",
    "    if (market_size_col is not None) and (market_size_col in d.columns):\n",
    "        # Unit-weighted (by market size) totals\n",
    "        w = market_summary[\"market_size_used\"].fillna(0.0)\n",
    "        total_dCS = float((market_summary[\"dCS\"] * w).sum())\n",
    "        total_delta_outside = float(market_summary[\"delta_outside\"].sum())\n",
    "        total_note = \"Weighted by provided market sizes\"\n",
    "    else:\n",
    "        # Simple averages across markets (per consumer CS)\n",
    "        total_dCS = float(market_summary[\"dCS\"].mean())\n",
    "        total_delta_outside = float(market_summary[\"delta_outside\"].mean())\n",
    "        total_note = \"Averaged across markets (no market size provided)\"\n",
    "\n",
    "    totals = {\n",
    "        \"total_dCS\": total_dCS,\n",
    "        \"total_delta_outside\": total_delta_outside,\n",
    "        \"note\": total_note\n",
    "    }\n",
    "\n",
    "    # Also return product-level predicted shares if you want them\n",
    "    product_shares = d[list(market_keys)+[\"nest\",\"prod_id\",\"s_base_pred\",\"s_new_pred\",\"s0_base_pred\",\"s0_new_pred\"]].copy()\n",
    "\n",
    "    return market_summary, totals, product_shares\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "alpha = float(iv.params[\"price\"])\n",
    "sigma = float(iv.params[\"ln_s_within\"])\n",
    "\n",
    "# Option A: everyone gets a +$0.50 tax\n",
    "mkt_sum, totals, sh = simulate_nested_welfare(df2, alpha, sigma, tax_scalar=0.50)\n",
    "\n",
    "# Option B: per-product deltas (e.g., a dict of UPC->Δp)\n",
    "# price_delta = {\"012345678901\": 0.20, \"098765432109\": 0.10}\n",
    "# mkt_sum, totals, sh = simulate_nested_welfare(df2, alpha, sigma, price_delta_map=price_delta)\n",
    "\n",
    "# Option C: if you pre-computed df2[\"price_cf\"], just call:\n",
    "# mkt_sum, totals, sh = simulate_nested_welfare(df2, alpha, sigma)\n",
    "\n",
    "print(\"\\nPer-market summary (first rows):\")\n",
    "print(mkt_sum.head())\n",
    "print(\"\\nTotals:\")\n",
    "print(totals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57367894-1cfb-487c-b3c9-6c0860b48c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Compute per-capita averages\n",
    "# -----------------------------\n",
    "# market_summary is the per-market output from simulate_nested_welfare(...)\n",
    "\n",
    "mkt_sum, totals, sh = simulate_nested_welfare(df2, alpha, sigma, tax_scalar = 0.40)\n",
    "\n",
    "\n",
    "# weighted average ΔCS per consumer (decrease in CS PER PACK, times average packs per month illinois)\n",
    "wa_dCS = (\n",
    "    (mkt_sum[\"dCS\"] * mkt_sum[\"market_size_used\"]).sum()\n",
    "    / mkt_sum[\"market_size_used\"].sum()\n",
    ")*(6.685*12 *0.2325)\n",
    "\n",
    "# weighted average change in outside-option share (Δ in share of non-bought PACKS \n",
    "wa_dS0 = (\n",
    "    (mkt_sum[\"delta_outside\"] * mkt_sum[\"market_size_used\"]).sum()\n",
    "    / mkt_sum[\"market_size_used\"].sum()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Scale up to Illinois totals\n",
    "# -----------------------------\n",
    "ILLINOIS_SMOKERS = 11_450_000 * 0.2325          # ≈ 2.661 million smokers\n",
    "COST_PER_SMOKER  = 1_810.63                     # yearly external social cost (USD)\n",
    "\n",
    "# total consumer surplus change (aggregate for all consumers)\n",
    "total_CS = wa_dCS * ILLINOIS_SMOKERS            # USD\n",
    "\n",
    "# change in number of smokers (negative if fewer smokers)\n",
    "delta_smokers = wa_dS0 * ILLINOIS_SMOKERS       # persons\n",
    "\n",
    "# social surplus gain from reduced smoking\n",
    "social_gain = delta_smokers * COST_PER_SMOKER  # USD (minus sign → fewer smokers increases welfare)\n",
    "\n",
    "# net welfare effect = social gain − consumer surplus loss\n",
    "net_effect = social_gain + total_CS\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Build publication-ready table\n",
    "# -----------------------------\n",
    "rows = [\n",
    "    [\"Weighted avg. ΔCS (per consumer, $)\", f\"{wa_dCS:,.2f}\"],\n",
    "    [\"Weighted avg. Δ outside share\", f\"{wa_dS0:.5f}\"],\n",
    "    [\"Illinois smokers (millions × share)\", f\"{ILLINOIS_SMOKERS/1e6:,.3f}\"],\n",
    "    [\"Aggregate ΔCS (Illinois, $)\", f\"{total_CS:,.0f}\"],\n",
    "    [\"Δ smokers (individuals)\", f\"{delta_smokers:,.0f}\"],\n",
    "    [\"Social gain from reduced smoking ($)\", f\"{social_gain:,.0f}\"],\n",
    "    [\"Net welfare = social − CS ($)\", f\"{net_effect:,.0f}\"],\n",
    "]\n",
    "table = pd.DataFrame(rows, columns=[\"Component\", \"Value\"])\n",
    "\n",
    "# pretty print\n",
    "print(\"\\n=== Welfare Decomposition: Statewide Effects of Cigarette Tax (Nested Logit) ===\")\n",
    "print(table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332b110-b538-4bdc-9559-0a16a2a3b8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
